{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf77556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import dotenv_values\n",
    "def read_envfile(path:Path):\n",
    "    env_vars = dict(dotenv_values(path))\n",
    "    return env_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92f1b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"SAGEMAKER_MODEL_SERVER_WORKERS\"': '1',\n",
       " '\"TS_DEFAULT_WORKERS_PER_MODEL\"': '1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_envfile(Path(\"../embedding.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b0fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {\"engine\": \"MPI\", \"option.model_id\": \"tiiuae/falcon-7b-instruct\", \"option.trust_remote_code\": \"true\", \"option.tensor_parallel_degree\": 1, \"option.paged_attention\": \"true\", \"option.max_rolling_batch_size\": 64, \"option.rolling_batch\": \"lmi-dist\", \"option.max_rolling_batch_prefill_tokens\": 1560}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb5e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../falcon-7b-instruct/serving.properties\", \"w\") as f:\n",
    "    for pro in properties.items():\n",
    "        p,v = pro\n",
    "        f.write(f\"{p}={v} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc7759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "smr_client =  boto3.client(\"sagemaker-runtime\")\n",
    "endpoint_name = \"lmi-model-2025-05-15-01-57-52-403\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abe63a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"generated_text\": \" listed as endangered in the United States. The diamondback terrapin is a small turtle found only in the coastal bays of the Atlantic coast of the United States. The diamondback terrapin is a land turtle that lives in brackish water. It is the only turtle in the world that can swim in both fresh and salt water.\\\\nThe diamondback terrapin is a small turtle that is found only in the coastal bays of the Atlantic coast of the United States. The diamondback terrapin is a land turtle that lives in brackish water. It is the only turtle in the world that can swim in both fresh and salt water.\\\\nThe diamondback terrapin is a small turtle that is found only in the coastal bays of the Atlantic coast of the United States. The diamondback terrapin is a land turtle that lives in brackish water. It is the only turtle in the world that can swim in both fresh and salt water. The diamondback terrapin is a small turtle that is found only in the coastal bays of\"}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(\n",
    "        {\n",
    "            \"inputs\": \"The diamondback terrapin was the first reptile to be\",\n",
    "            \"parameters\": {\n",
    "                \"do_sample\": True,\n",
    "                \"max_new_tokens\": 256,\n",
    "                \"min_new_tokens\": 256,\n",
    "                \"temperature\": 0.3,\n",
    "                \"watermark\": True,\n",
    "            },\n",
    "        }\n",
    "    ),\n",
    "    ContentType=\"application/json\",\n",
    ")[\"Body\"].read().decode(\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda0e4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mrafi/Desktop/Books/RAGwithSagemaker/research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b8ec530",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "550fe276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mrafi/Desktop/Books/RAGwithSagemaker'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b59a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e2c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "from langchain.vectorstores import Chroma, AtlasDB, FAISS\n",
    "from RAGwithSagemaker.logging.logging import logger\n",
    "\n",
    "def vectorizedocs(embeddings):\n",
    "    logger.info(\"starting docs  loadig\")\n",
    "    loader = PyPDFDirectoryLoader(\"RAGwithSagemaker/data\")\n",
    "    docs = loader.load()\n",
    "    logger.info(\"docs loaded\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "    final_docs = text_splitter.split_documents(docs)\n",
    "    logger.info(\"starting vector dbs\")\n",
    "    vector_store = FAISS.from_documents(final_docs, embeddings)\n",
    "    # with open(\"vector_store.pth\", \"wb\") as file:           # Optional. Helps in resuing the vectorspace directly without processing the files everytime\n",
    "    #     vector_store = torch.save(vector_store,file)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c103c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 21:54:07,149, common.py, 19, INFO, config/config.yaml file loaded sucessfully\n",
      "2025-05-14 21:54:07,152, common.py, 19, INFO, params.yaml file loaded sucessfully\n",
      "2025-05-14 21:54:07,153, common.py, 19, INFO, schema.yaml file loaded sucessfully\n",
      "2025-05-14 21:54:07,155, common.py, 32, INFO, Directory model created\n",
      "2025-05-14 21:54:07,233, 3111586173.py, 25, INFO, Started vector db\n",
      "2025-05-14 21:54:07,234, vectorize_docs.py, 11, INFO, starting docs  loadig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SAGEMAKER_MODEL_SERVER_WORKERS': '1', 'TS_DEFAULT_WORKERS_PER_MODEL': '1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 21:54:13,962, vectorize_docs.py, 14, INFO, docs loaded\n",
      "2025-05-14 21:54:13,988, vectorize_docs.py, 17, INFO, starting vector dbs\n"
     ]
    }
   ],
   "source": [
    "from RAGwithSagemaker.config.configuration import ConfigurationManager\n",
    "from RAGwithSagemaker.cloud.embeddingmodel import DeployEmbeddingModel\n",
    "from RAGwithSagemaker.cloud.textgenerationmodel import DeployTextGenerationModel\n",
    "from RAGwithSagemaker.cloud.ragendpoints import RAGEndPoints\n",
    "from RAGwithSagemaker.cloud.vectorize_docs import vectorizedocs\n",
    "from RAGwithSagemaker.logging.logging import logger\n",
    "\n",
    "\n",
    "congfiguration = ConfigurationManager()\n",
    "sagemaker_config = congfiguration.get_sagemakersession_config()\n",
    "embeddings_config = congfiguration.get_embeddings_config()\n",
    "textgeneration_config = congfiguration.get_textgeneration_config()\n",
    "s3_config = congfiguration.get_s3_config()\n",
    "rag_config = congfiguration.get_rag_config()\n",
    "\n",
    "# text_model_deploy =DeployTextGenerationModel(sagemaker_config, textgeneration_config)\n",
    "# text_model_deploy.creat_and_deploy_model()\n",
    "\n",
    "# embedding_model_deploy = DeployEmbeddingModel(sagemaker_config,embeddings_config )\n",
    "# embedding_model_deploy.deploy_embedding_model()\n",
    "\n",
    "rag_endpoints = RAGEndPoints(rag_config)\n",
    "embeddings_endpoint, sm_llm_endpoint = rag_endpoints.create_rag_endpoints()\n",
    "\n",
    "logger.info(\"Started vector db\")\n",
    "vector_store = vectorizedocs(embeddings_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8cfb2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_stuff_documents_chain' from 'langchain.chains.combine_documents' (/home/mrafi/miniconda3/envs/rag/lib/python3.10/site-packages/langchain/chains/combine_documents/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine_documents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_stuff_documents_chain\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_retrieval_chain\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstreamlit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mst\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_stuff_documents_chain' from 'langchain.chains.combine_documents' (/home/mrafi/miniconda3/envs/rag/lib/python3.10/site-packages/langchain/chains/combine_documents/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import streamlit as st\n",
    "import torch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
