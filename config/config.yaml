artifacts_root: model
sagemaker:
  role: "arn:aws:iam::703671901662:role/service-role/AmazonSageMaker-ExecutionRole-20250211T170358"
  bucket: mlflowtrackingrafi
  default_bucket_prefix: model
embeddings:
  instance_type: "ml.g5.4xlarge"
  model_version: "*"
  model_id: "huggingface-textembedding-gpt-j-6b-fp16"
  model_scope: inference
  image_scope: inference
  role: "arn:aws:iam::703671901662:role/service-role/AmazonSageMaker-ExecutionRole-20250211T170358"


textgenartion:
  model_folder: model
  servingproperties:
    engine: MPI
    option.tensor_parallel_degree: 1
    option.rolling_batch: auto
    option.max_rolling_batch_size: 8
    option.model_loading_timeout: 3600
    option.model_id: s3://sagemaker-example-files-prod-us-east-1/models/llama-2/fp16/7B/
    option.paged_attention: "true"
    option.trust_remote_code: "true"
    option.dtype: fp16
    option.enable_streaming: "False"
  model:
    model_name: meta-llama/Llama-2-7b-fp16
    properties_file: tiiuae
  image: 
    framework: "djl-deepspeed"
    version: "0.23.0"
  instance_type: "ml.g5.12xlarge"
  base_name_endpoint: "lmi-model"
  s3_code_prefix: "large-model-lmi/code"
s3: 
  s3_code_prefix: model
  bucket: mlflowtrackingrafi
aoss:
  region: 'us-east-1'
  host: 'yvi7ktac3durmnl69mc9.us-east-1.aoss.amazonaws.com'
  service: 'aoss'
